{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to autoreload the module without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mppi import InputFiles as I, Calculators as C, Datasets as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [{'a' : 1},{'a' : 2, 'b' : 2},{'a' : 3, 'b' : 3, 'c' : 3}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1}, {'a': 2, 'b': 2}, {'a': 3, 'b': 3, 'c': 3}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if {'a' : 3, 'b' : 3} in ids : print('si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for the Dataset module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is the class used to build, perform and post-process a set made of several calculation performed both with QuantumESPRESSO and Yambo.\n",
    "\n",
    "Here we discuss some explicit examples to describe the usage and the main features of the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a convergence analysis for the gs energy of Silicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this class to find the value of the energy cutoff that guarantees a converged result for the\n",
    "ground state energy of Silicon.\n",
    "\n",
    "We start from a given input file for Silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'control': {'verbosity': \"'high'\",\n",
       "  'pseudo_dir': \"'../pseudos'\",\n",
       "  'calculation': \"'scf'\",\n",
       "  'prefix': \"'si_scf'\"},\n",
       " 'system': {'force_symmorphic': '.true.',\n",
       "  'occupations': \"'fixed'\",\n",
       "  'ibrav': '2',\n",
       "  'celldm(1)': '10.3',\n",
       "  'ntyp': '1',\n",
       "  'nat': '2',\n",
       "  'ecutwfc': '40'},\n",
       " 'electrons': {'conv_thr': '1e-08'},\n",
       " 'ions': {},\n",
       " 'cell': {},\n",
       " 'atomic_species': {'Si': ['28.086', 'Si.pbe-mt_fhi.UPF']},\n",
       " 'atomic_positions': {'type': 'crystal',\n",
       "  'values': [['Si', [0.125, 0.125, 0.125]], ['Si', [-0.125, -0.125, -0.125]]]},\n",
       " 'kpoints': {'type': 'automatic',\n",
       "  'values': ([4.0, 4.0, 4.0], [0.0, 0.0, 0.0])},\n",
       " 'cell_parameters': {},\n",
       " 'file': 'IO_files/si_scf.in'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = I.PwInput(file='IO_files/si_scf.in')\n",
    "inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we define a Calculator that will be used by the Dataset class to run the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a parallel QuantumESPRESSO calculator with scheduler direct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'omp': 1,\n",
       " 'executable': 'pw.x',\n",
       " 'multiTask': True,\n",
       " 'scheduler': 'direct',\n",
       " 'mpi_run': 'mpirun -np 2',\n",
       " 'cpus_per_task': 4,\n",
       " 'ntasks': 3,\n",
       " 'skip': True,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = C.QeCalculator(mpi_run='mpirun -np 2', skip = True)\n",
    "code.global_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the instance of Dataset to perform the convergence procedure. Some information of the class\n",
    "can be read as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'runs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Class to perform a set of calculations and to manage the associated results.\n",
       "\n",
       "Attributes:\n",
       "    label (:py:class:`str`): the label of the dataset, it can be useful for instance if more\n",
       "    than one istance of the class is present\n",
       "    run_dir (:py:class:`str`): path of the directory where the runs will be performed\n",
       "    **kwargs : all the parameters passed to the dataset and stored in its _global_options.\n",
       "    Can be useful, for instance, in performing a post-processing of the results.\n",
       "\n",
       "Example:\n",
       "    >>> code = QeCalculator()\n",
       "    >>> study=Dataset(label = .., run_dir = ..., **kwargs)\n",
       "    >>> study.append_run(id={'ecut': 30, 'kpoints' : 4},input=...,runner=code)\n",
       "    >>> study.append_run(id={'ecut': 40, 'kpoints' : 4},input=...,runner=code)\n",
       "    >>> study.run()\n",
       "\u001b[0;31mInit docstring:\u001b[0m Set the dataset ready for appending new runs\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Applications/MPPI/mppi/Datasets/Dataset.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D.Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_convergence = D.Dataset(label='Si_gs_convergence',run_dir='Si_gs_convergence', spin_orbit = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset inherit from Runner so it has the same structure and we can use the same methods of QeCalculator and YamboCalculator \n",
    "to access to its global options. \n",
    "\n",
    "Note that in this case we have defined a spin_orbit variable that can be used later. This variables is \n",
    "stored in the global options of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Si_gs_convergence',\n",
       " 'run_dir': 'Si_gs_convergence',\n",
       " 'spin_orbit': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.global_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to append to the Dataset all the calculation that we want to peform lately.\n",
    "\n",
    "For instance we can perform first a set of calculations in function of the cutoff energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_cutoffs = [20,30,40,50] # in Ry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in energy_cutoffs:\n",
    "    idd = {'eng_cut' : e} #id that identifies the run in the Dataset\n",
    "    inp.set_prefix(D.name_from_id(idd)) #attribute the id as the prefix of the input\n",
    "    inp.set_energy_cutoff(e)\n",
    "    gs_convergence.append_run(id=idd,runner=code,input=inp, other_variables = e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The append_run method set the attribute of the object, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'eng_cut': 20}, {'eng_cut': 30}, {'eng_cut': 40}, {'eng_cut': 50}]\n",
      "['eng_cut_20', 'eng_cut_30', 'eng_cut_40', 'eng_cut_50']\n",
      "[{'calc': <mppi.Calculators.QeCalculator.QeCalculator object at 0x7fdadd51fcf8>, 'runs': [0, 1, 2, 3]}]\n"
     ]
    }
   ],
   "source": [
    "print(gs_convergence.ids) # identify each element of the dataset\n",
    "print(gs_convergence.names) # name of the input file written on disk\n",
    "print(gs_convergence.calculators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the input files is evaluated from the ids using the function name_from_id.\n",
    "\n",
    "gs_convergence.runs is a list that contains the merge of the input object and the global options for each of the\n",
    "appended run, in this way one can check which is the input associated.\n",
    "Other variables passed in the append run are stored in the runs attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Si_gs_convergence',\n",
       " 'run_dir': 'Si_gs_convergence',\n",
       " 'spin_orbit': False,\n",
       " 'input': {'control': {'verbosity': \"'high'\",\n",
       "   'pseudo_dir': \"'../pseudos'\",\n",
       "   'calculation': \"'scf'\",\n",
       "   'prefix': \"'eng_cut_40'\"},\n",
       "  'system': {'force_symmorphic': '.true.',\n",
       "   'occupations': \"'fixed'\",\n",
       "   'ibrav': '2',\n",
       "   'celldm(1)': '10.3',\n",
       "   'ntyp': '1',\n",
       "   'nat': '2',\n",
       "   'ecutwfc': 40},\n",
       "  'electrons': {'conv_thr': '1e-08'},\n",
       "  'ions': {},\n",
       "  'cell': {},\n",
       "  'atomic_species': {'Si': ['28.086', 'Si.pbe-mt_fhi.UPF']},\n",
       "  'atomic_positions': {'type': 'crystal',\n",
       "   'values': [['Si', [0.125, 0.125, 0.125]],\n",
       "    ['Si', [-0.125, -0.125, -0.125]]]},\n",
       "  'kpoints': {'type': 'automatic',\n",
       "   'values': ([4.0, 4.0, 4.0], [0.0, 0.0, 0.0])},\n",
       "  'cell_parameters': {},\n",
       "  'file': 'IO_files/si_scf.in'},\n",
       " 'other_variables': 40}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.runs[2] #give the parameters of the third computation appended to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute .calculator is a dictionary that is empty before the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before run the Dataset we can add another computation, made with a different calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a parallel QuantumESPRESSO calculator with scheduler direct\n"
     ]
    }
   ],
   "source": [
    "code2 = C.QeCalculator(omp = 2, mpi_run='mpirun -np 2',skip=True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = I.PwInput() #activate this line to produce an empty input that produces a CRASH in the simulation\n",
    "idd = 'code_number2' # we can use a string as id of the run\n",
    "inp.set_prefix(D.name_from_id(idd))\n",
    "inp.set_energy_cutoff(60)\n",
    "gs_convergence.append_run(id=idd,runner=code2,input=inp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'eng_cut': 20}, {'eng_cut': 30}, {'eng_cut': 40}, {'eng_cut': 50}, 'code_number2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'calc': <mppi.Calculators.QeCalculator.QeCalculator at 0x7fdadd57cf60>,\n",
       "  'runs': [0, 1, 2, 3]},\n",
       " {'calc': <mppi.Calculators.QeCalculator.QeCalculator at 0x7fdadd51f1d0>,\n",
       "  'runs': [4]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_convergence.ids)\n",
    "gs_convergence.calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Si_gs_convergence',\n",
       " 'run_dir': 'Si_gs_convergence',\n",
       " 'spin_orbit': False,\n",
       " 'input': {'control': {'verbosity': \"'high'\",\n",
       "   'pseudo_dir': \"'../pseudos'\",\n",
       "   'calculation': \"'scf'\",\n",
       "   'prefix': \"'code_number2'\"},\n",
       "  'system': {'force_symmorphic': '.true.',\n",
       "   'occupations': \"'fixed'\",\n",
       "   'ibrav': '2',\n",
       "   'celldm(1)': '10.3',\n",
       "   'ntyp': '1',\n",
       "   'nat': '2',\n",
       "   'ecutwfc': 60},\n",
       "  'electrons': {'conv_thr': '1e-08'},\n",
       "  'ions': {},\n",
       "  'cell': {},\n",
       "  'atomic_species': {'Si': ['28.086', 'Si.pbe-mt_fhi.UPF']},\n",
       "  'atomic_positions': {'type': 'crystal',\n",
       "   'values': [['Si', [0.125, 0.125, 0.125]],\n",
       "    ['Si', [-0.125, -0.125, -0.125]]]},\n",
       "  'kpoints': {'type': 'automatic',\n",
       "   'values': ([4.0, 4.0, 4.0], [0.0, 0.0, 0.0])},\n",
       "  'cell_parameters': {},\n",
       "  'file': 'IO_files/si_scf.in'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.runs[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that all the computation have been added we can run the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input eng_cut_20\n",
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input eng_cut_30\n",
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input eng_cut_40\n",
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input eng_cut_50\n",
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input code_number2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Si_gs_convergence/eng_cut_20.save/data-file-schema.xml',\n",
       " 1: 'Si_gs_convergence/eng_cut_30.save/data-file-schema.xml',\n",
       " 2: 'Si_gs_convergence/eng_cut_40.save/data-file-schema.xml',\n",
       " 3: 'Si_gs_convergence/eng_cut_50.save/data-file-schema.xml',\n",
       " 4: 'Si_gs_convergence/code_number2.save/data-file-schema.xml'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run method returns the attribute .results of the Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Si_gs_convergence/eng_cut_20.save/data-file-schema.xml',\n",
       " 1: 'Si_gs_convergence/eng_cut_30.save/data-file-schema.xml',\n",
       " 2: 'Si_gs_convergence/eng_cut_40.save/data-file-schema.xml',\n",
       " 3: 'Si_gs_convergence/eng_cut_50.save/data-file-schema.xml',\n",
       " 4: 'Si_gs_convergence/code_number2.save/data-file-schema.xml'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation allows us to parse the data after the execution of the dataset and/or to choose a parser \n",
    "among several choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to perform the parsing of the results is _a posteriori_ from the run of the dataset.\n",
    "\n",
    "For instance we can parse the results with the PwParser class of this package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse file : Si_gs_convergence/eng_cut_20.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/eng_cut_30.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/eng_cut_40.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/eng_cut_50.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/code_number2.save/data-file-schema.xml\n"
     ]
    }
   ],
   "source": [
    "from mppi import Parsers as P\n",
    "\n",
    "results = {}\n",
    "for run,data in gs_convergence.results.items():\n",
    "    results[run] = P.PwParser(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd5fd518>,\n",
       " 1: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd5bb588>,\n",
       " 2: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd5bb438>,\n",
       " 3: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd56fb70>,\n",
       " 4: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd526f28>}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results associate to the key \"i\" correspond to the i-th element appended to the run.\n",
    "\n",
    "The input parameters associated to each key of results are written inside the gs_convergence_runs[key] list.\n",
    "\n",
    "For instance the total energy is extracted as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0 energy -7.870821313426413\n",
      "run 1 energy -7.872953197509275\n",
      "run 2 energy -7.874327291306248\n",
      "run 3 energy -7.874492376334014\n",
      "run 4 energy -7.874513952356973\n"
     ]
    }
   ],
   "source": [
    "for run,res in results.items():\n",
    "    print('run',run,'energy',res.get_energy(convert_eV=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the post processing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Parsing, or other more specific procedures, can be performed directly when the run method is called.\n",
    "\n",
    "To do so, we define a post processing function and pass it to the Dataset. \n",
    "\n",
    "The class will apply this function when the run method of Dataset is called. For istance in this way we can directly \n",
    "extract the total energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_energy(dataset): \n",
    "    from mppi import Parsers as P\n",
    "    energy = {}\n",
    "    for run,data in dataset.results.items():\n",
    "        results = P.PwParser(data,verbose=False)\n",
    "        energy[run] = results.get_energy(convert_eV = False)\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_convergence.set_postprocessing_function(extract_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that the post processing function is passed to dataset it is directly applied when the run is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -7.870821313426413,\n",
       " 1: -7.872953197509275,\n",
       " 2: -7.874327291306248,\n",
       " 3: -7.874492376334014,\n",
       " 4: -7.874513952356973}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.update_global_options(verbose=False)\n",
    "code2.update_global_options(verbose=False)\n",
    "gs_convergence.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the attribute results contains always the name of the xml data, the post processed results\n",
    "can be accessed in the class as self.post_processing(). \n",
    "\n",
    "For this reason the method fetch_results has been slightly modified with respect to the original implementation\n",
    "of PyBigDFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the fetch_results method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible approach is to define a post processing function that perform a simple parsing of the data.\n",
    "\n",
    "Then we can use fetch_results to seek for the attribute energy in the computation(s) that match the id \n",
    "passed in fetch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(dataset):\n",
    "    from mppi import Parsers as P\n",
    "    results = {}\n",
    "    for run,data in dataset.results.items():\n",
    "        results[run] = P.PwParser(data,verbose=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_convergence.set_postprocessing_function(parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd562630>,\n",
       " 1: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd7a7cc0>,\n",
       " 2: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd4d2320>,\n",
       " 3: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd4a0630>,\n",
       " 4: <mppi.Parsers.PwParser.PwParser at 0x7f4dfd44aba8>}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-7.874492376334014]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.fetch_results(id={'eng_cut': 50},attribute='energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the seek_convergence method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the functionality of this method by performing a second convergence test on the number of kpoints.\n",
    "\n",
    "In this example we set the energy cutoff to 60 Ry and build a new dataset appending run with increasing number of\n",
    "kpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = I.PwInput('IO_files/si_scf.in')\n",
    "inp.set_energy_cutoff(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a QuantumESPRESSO calculator with OMP_NUM_THREADS=1 and command mpirun -np 4 pw.x\n"
     ]
    }
   ],
   "source": [
    "code = C.QeCalculator(skip=True,verbose=False)\n",
    "#code.global_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kpoint = D.Dataset(label='Si_kpoints_convergence',run_dir='Si_gs_convergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpoints = [2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in kpoints:\n",
    "    id = {'kp':k}\n",
    "    inp.set_kpoints(points = [k,k,k])\n",
    "    inp.set_prefix(D.name_from_id(id))\n",
    "    gs_kpoint.append_run(id=id,runner=code,input=inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runs have been appended but not performed, then we call seek_convergence.\n",
    "\n",
    "We want to perform a convergence procedure based on the value of the total energy of the system.\n",
    "So we can use the post processing function that directly provides this quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kpoint.set_postprocessing_function(extract_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching results for id \" {'kp': 2} \"\n",
      "Fetching results for id \" {'kp': 3} \"\n",
      "Fetching results for id \" {'kp': 4} \"\n",
      "Fetching results for id \" {'kp': 5} \"\n",
      "Convergence reached in Dataset \"Si_kpoints_convergence\" for id \" {'kp': 4} \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'kp': 4}, -7.874513952262473)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_kpoint.seek_convergence(rtol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seek_converge runs all the computation (in the order provided by append_run) until convergence is reached.\n",
    "Otherwise it is possible to pass a list of ids as argument of the method, in this case the calculation are restricted\n",
    "to the simulations associated to the provided ids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use a more generic post processing function that simply parse the data.\n",
    "In this case we can choose which quantity is used to check if the convergence is reached by specifying the attribute = ...\n",
    "options in the call of the seek_convergence. For instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kpoint.set_postprocessing_function(parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching results for id \" {'kp': 2} \"\n",
      "Fetching results for id \" {'kp': 3} \"\n",
      "Fetching results for id \" {'kp': 4} \"\n",
      "Fetching results for id \" {'kp': 5} \"\n",
      "Convergence reached in Dataset \"Si_kpoints_convergence\" for id \" {'kp': 4} \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'kp': 4}, -7.874513952262473)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_kpoint.seek_convergence(rtol=0.001,attribute='energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a convergence test for Hartree-Fock computations with Yambo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a set of Hartree-Fock computation for silicon and we look for the value of the EXXRLvcs that ensure\n",
    "a converged value of the direct gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need a nscf computation. We start from scf result with ecutoff = 60 and kpoints = [4,4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = I.PwInput('Si_gs_convergence/kp_4.in')\n",
    "inp.set_nscf(8)\n",
    "inp.set_kpoints(points = [6,6,6]) #nscf kpoints can be different from the scf\n",
    "name = 'nscf_kp6_ecut60'\n",
    "inp.set_prefix(name)\n",
    "#inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a QuantumESPRESSO calculator with OMP_NUM_THREADS=1 and command mpirun -np 4 pw.x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'omp': 1,\n",
       " 'mpi_run': 'mpirun -np 4',\n",
       " 'executable': 'pw.x',\n",
       " 'skip': False,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = C.QeCalculator()\n",
    "code.global_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete log file: Si_gs_convergence/nscf_kp6_ecut60.log\n",
      "delete xml file: Si_gs_convergence/nscf_kp6_ecut60.xml\n",
      "delete folder: Si_gs_convergence/nscf_kp6_ecut60.save\n",
      "Copy source_dir Si_gs_convergence/kp_4.save in the Si_gs_convergence/nscf_kp6_ecut60.save\n",
      "Run directory Si_gs_convergence\n",
      "Executing command: mpirun -np 4 pw.x -inp nscf_kp6_ecut60.in > nscf_kp6_ecut60.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Si_gs_convergence/nscf_kp6_ecut60.save/data-file-schema.xml'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.run(run_dir='Si_gs_convergence',input=inp,name=name,source_dir='Si_gs_convergence/kp_4.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the generation of the run_dir and SAVE folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mppi import Utilities as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = 'Si_hf_convergence'\n",
    "source_dir = 'Si_gs_convergence/nscf_kp6_ecut60.save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create folder Si_hf_convergence\n",
      "Executing command: cd Si_gs_convergence/nscf_kp6_ecut60.save; p2y -a 2\n",
      "Executing command: cp -r Si_gs_convergence/nscf_kp6_ecut60.save/SAVE Si_hf_convergence\n",
      "Executing command: cd Si_hf_convergence;OMP_NUM_THREADS=1 yambo\n"
     ]
    }
   ],
   "source": [
    "U.build_SAVE(source_dir,run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build the Yambo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a Yambo calculator with OMP_NUM_THREADS=1 and command mpirun -np 4 yambo\n"
     ]
    }
   ],
   "source": [
    "code = C.YamboCalculator(skip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': 'yambo -x -V rl',\n",
       " 'folder': 'Si_hf_convergence',\n",
       " 'filename': 'yambo.in',\n",
       " 'arguments': ['HF_and_locXC'],\n",
       " 'variables': {'FFTGvecs': [2733.0, 'RL'],\n",
       "  'SE_Threads': [0.0, ''],\n",
       "  'EXXRLvcs': [17153.0, 'RL'],\n",
       "  'QPkrange': [[1, 1, 1, 8], '']}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = I.YamboInput(args='yambo -x -V rl',folder=run_dir)\n",
    "# we are interested at the direct gap at Gamma so we include only the first kpoint\n",
    "inp['variables']['QPkrange'] = [[1,1,1,8],'']\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_convergence = D.Dataset(label='Si_hf',run_dir=run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by adding some computations to see how to manage the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exx_values = [1.,2.,3.,4.] #in Hartree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exx_values:\n",
    "    id = {'exxrl' : e}\n",
    "    inp['variables']['EXXRLvcs'] = [1e3*e, 'mHa']\n",
    "    hf_convergence.append_run(id=id,input=inp,runner=code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If needed we can also pass the jobname attribute by adding, for istance\n",
    " \n",
    " jobname=D.name_from_id(id)+'-job' \n",
    " \n",
    " in the appen_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run directory Si_hf_convergence\n",
      "Skip the computation for input exxrl_1.0\n",
      "Run directory Si_hf_convergence\n",
      "Skip the computation for input exxrl_2.0\n",
      "Run directory Si_hf_convergence\n",
      "Skip the computation for input exxrl_3.0\n",
      "Run directory Si_hf_convergence\n",
      "Skip the computation for input exxrl_4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'output': ['Si_hf_convergence/exxrl_1.0/o-exxrl_1.0.hf'],\n",
       "  'ndb': ['Si_hf_convergence/exxrl_1.0/ndb.HF_and_locXC']},\n",
       " 1: {'output': ['Si_hf_convergence/exxrl_2.0/o-exxrl_2.0.hf'],\n",
       "  'ndb': ['Si_hf_convergence/exxrl_2.0/ndb.HF_and_locXC']},\n",
       " 2: {'output': ['Si_hf_convergence/exxrl_3.0/o-exxrl_3.0.hf'],\n",
       "  'ndb': ['Si_hf_convergence/exxrl_3.0/ndb.HF_and_locXC']},\n",
       " 3: {'output': ['Si_hf_convergence/exxrl_4.0/o-exxrl_4.0.hf'],\n",
       "  'ndb': ['Si_hf_convergence/exxrl_4.0/ndb.HF_and_locXC']}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_convergence.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the results with a post processing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a general post processing function to extract all the results from the o- files of the dataset.\n",
    "\n",
    "We can use the YamboParser class of this package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(dataset):\n",
    "    from mppi import Parsers as P\n",
    "    results = {}\n",
    "    for run,data in dataset.results.items():\n",
    "        results[run] = P.YamboParser(data['output'],verbose=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_convergence.set_postprocessing_function(parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse file Si_hf_convergence/exxrl_1.0/o-exxrl_1.0.hf\n",
      "Parse file Si_hf_convergence/exxrl_2.0/o-exxrl_2.0.hf\n",
      "Parse file Si_hf_convergence/exxrl_3.0/o-exxrl_3.0.hf\n",
      "Parse file Si_hf_convergence/exxrl_4.0/o-exxrl_4.0.hf\n"
     ]
    }
   ],
   "source": [
    "code.update_global_options(verbose=False,skip=True)\n",
    "results = hf_convergence.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be extracted as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-19.05416   -1.101     -1.067     -1.62535    6.79846    6.790734\n",
      "   6.649487   7.654567]\n",
      "[-19.13128   -1.552     -1.519     -2.08017    6.501243   6.493162\n",
      "   6.351671   7.156224]\n",
      "[-19.16567   -1.701     -1.667     -2.22218    6.34695    6.329222\n",
      "   6.187717   6.996501]\n",
      "[-19.17205   -1.718     -1.684     -2.23912    6.328658   6.310536\n",
      "   6.169065   6.977456]\n"
     ]
    }
   ],
   "source": [
    "for irun in results:\n",
    "    print(results[irun]['hf']['ehf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the direct gap with a post processing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We describe the usage of a post processing function to perform a more specific operation like computing\n",
    "the direct band gap. We define the post processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direct_gap(dataset):\n",
    "    \"\"\"\"\n",
    "    Compute the direct band gap assuming that there is only one kpoint.\n",
    "    The arguments energy_col, val_band and cond_band are read from the global_options\n",
    "    of the dataset.\n",
    "    \"\"\"\n",
    "    from mppi import Parsers as P\n",
    "    import numpy as np\n",
    "    glob_opt = dataset.global_options()\n",
    "    val_band = glob_opt.get('val_band',1)\n",
    "    cond_band = glob_opt.get('cond_band',1)\n",
    "    # the name of the column used to compute the gap\n",
    "    energy_col = glob_opt.get('energy_col','hf') \n",
    "    gap = {}\n",
    "    for run,data in dataset.results.items():\n",
    "        results = P.YamboParser(data['output'])\n",
    "        key = list(results.keys())[0] # select the key (can be hf or qp)\n",
    "        bands = results[key]['band']\n",
    "        index_val = np.where(bands == val_band)\n",
    "        index_cond = np.where(bands == cond_band)\n",
    "        energy = results[key][energy_col]\n",
    "        delta = energy[index_cond]-energy[index_val]\n",
    "        gap[run] = float(delta)\n",
    "    return gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function assume that some input like the specification of the conduction and valence bands are given in the global options\n",
    "of the dataset. So we can se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_convergence.update_global_options(val_band = 4, cond_band = 5, energy_col = 'hf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we set the new post processing function and run the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_convergence.set_postprocessing_function(get_direct_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6.5168870000000005, 1: 6.67449, 2: 6.662207, 3: 6.660855000000001}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_convergence.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of seek convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The post processing function defined above can be used together with the seek_convergence method to perform a convergence study\n",
    "\n",
    "In this case we define a new dataset and append many possible runs. Only those one needed to reach the given tolerance will be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_convergence2 = D.Dataset(label='Si_hf',run_dir=run_dir,val_band = 4, cond_band = 5, var_name = 'hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exx_values = [float(i) for i in range(1,10)] #in Hartree\n",
    "exx_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exx_values:\n",
    "    id = {'exxrl' : e}\n",
    "    inp['variables']['EXXRLvcs'] = [1e3*e, 'mHa']\n",
    "    hf_convergence2.append_run(id=id,input=inp,runner=code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_convergence2.set_postprocessing_function(get_direct_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching results for id \" {'exxrl': 1.0} \"\n",
      "Fetching results for id \" {'exxrl': 2.0} \"\n",
      "Fetching results for id \" {'exxrl': 3.0} \"\n",
      "Fetching results for id \" {'exxrl': 4.0} \"\n",
      "Fetching results for id \" {'exxrl': 5.0} \"\n",
      "Fetching results for id \" {'exxrl': 6.0} \"\n",
      "Convergence reached in Dataset \"Si_hf\" for id \" {'exxrl': 5.0} \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'exxrl': 5.0}, 6.661784)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_convergence2.seek_convergence(rtol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
