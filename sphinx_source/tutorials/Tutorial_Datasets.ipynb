{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to autoreload the module without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mppi import InputFiles as I, Calculators as C, Datasets as D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for the Dataset module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is the class used to build, perform and post-process a set made of several calculation performed both with QuantumESPRESSO and Yambo.\n",
    "\n",
    "Here we discuss some explicit examples to describe the usage and the main features of the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a convergence analysis for the gs energy of Silicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this class to find the value of the energy cutoff that guarantees a converged result for the\n",
    "ground state energy of Silicon.\n",
    "\n",
    "We start from a given input file for Silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = I.PwInput(file='IO_files/si_scf.in')\n",
    "#inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we define a Calculator that will be used by the Dataset class to run the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a QuantumESPRESSO calculator with OMP_NUM_THREADS=1 and command mpirun -np 4 pw.x\n"
     ]
    }
   ],
   "source": [
    "code = C.QeCalculator(omp = 1, mpi_run='mpirun -np 4', skip = True, verbose= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the instance of Dataset to perform the convergence procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_convergence = D.Dataset(label='Si_gs_convergence',run_dir='Si_gs_convergence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset inherit from Runner so it has the same structure and we can use the same methods of QeCalculator and YamboCalculator \n",
    "to access to its global options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Si_gs_convergence', 'run_dir': 'Si_gs_convergence'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.global_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to append to the Dataset all the calculation that we want to peform lately.\n",
    "\n",
    "For instance we can perform first a set of calculations in function of the cutoff energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mppi.Utilities import Utils as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_cutoffs = [20,30,40,50] # in Ry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in energy_cutoffs:\n",
    "    idd = {'eng_cut' : e} #id that identifies the run in the Dataset\n",
    "    inp.set_prefix(U.name_from_id(idd)) #attribute the id as the prefix of the input\n",
    "    inp.set_energy_cutoff(e)\n",
    "    gs_convergence.append_run(id=idd,runner=code,input=inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The append_run method set the attribute of the object, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'eng_cut': 20}, {'eng_cut': 30}, {'eng_cut': 40}, {'eng_cut': 50}]\n",
      "['eng_cut_20', 'eng_cut_30', 'eng_cut_40', 'eng_cut_50']\n",
      "[{'calc': <mppi.Calculators.QeCalculator.QeCalculator object at 0x7f15a818d518>, 'runs': [0, 1, 2, 3]}]\n"
     ]
    }
   ],
   "source": [
    "print(gs_convergence.ids) # idensify each element of the dataset\n",
    "print(gs_convergence.names) # name of the input file written on disk\n",
    "print(gs_convergence.calculators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gs_convergence.runs is a list that contains the merge of the input object and the global options for each of the\n",
    "appended run, in this way one can check which is the input associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Si_gs_convergence',\n",
       " 'run_dir': 'Si_gs_convergence',\n",
       " 'input': {'control': {'verbosity': \"'high'\",\n",
       "   'pseudo_dir': \"'../pseudos'\",\n",
       "   'calculation': \"'scf'\",\n",
       "   'prefix': \"'eng_cut_40'\"},\n",
       "  'system': {'force_symmorphic': '.true.',\n",
       "   'occupations': \"'fixed'\",\n",
       "   'ibrav': '2',\n",
       "   'celldm(1)': '10.3',\n",
       "   'ntyp': '1',\n",
       "   'nat': '2',\n",
       "   'ecutwfc': 40},\n",
       "  'electrons': {'conv_thr': '1e-08'},\n",
       "  'ions': {},\n",
       "  'cell': {},\n",
       "  'atomic_species': {'Si': ['28.086', 'Si.pbe-mt_fhi.UPF']},\n",
       "  'atomic_positions': {'type': 'crystal',\n",
       "   'values': [['Si', [0.125, 0.125, 0.125]],\n",
       "    ['Si', [-0.125, -0.125, -0.125]]]},\n",
       "  'kpoints': {'type': 'automatic',\n",
       "   'values': ([4.0, 4.0, 4.0], [0.0, 0.0, 0.0])},\n",
       "  'cell_parameters': {},\n",
       "  'file': 'IO_files/si_scf.in'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.runs[2] #give the parameters of the third computation appended to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute .calculator is a dictionary that is empty before the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before run the Dataset we can add another computation, made with a different calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a QuantumESPRESSO calculator with OMP_NUM_THREADS=1 and command mpirun -np 2 pw.x\n"
     ]
    }
   ],
   "source": [
    "code2 = C.QeCalculator(omp = 1, mpi_run='mpirun -np 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idd = 'code_number2' # we can use a string as id of the run\n",
    "inp.set_prefix(U.name_from_id(idd))\n",
    "inp.set_energy_cutoff(60)\n",
    "gs_convergence.append_run(id=idd,runner=code2,input=inp,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'eng_cut': 20}, {'eng_cut': 30}, {'eng_cut': 40}, {'eng_cut': 50}, 'code_number2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'calc': <mppi.Calculators.QeCalculator.QeCalculator at 0x7f15a818d518>,\n",
       "  'runs': [0, 1, 2, 3]},\n",
       " {'calc': <mppi.Calculators.QeCalculator.QeCalculator at 0x7f15a80a1278>,\n",
       "  'runs': [4]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_convergence.ids)\n",
    "gs_convergence.calculators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that all the computation have been added we can run the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input  eng_cut_20\n",
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input  eng_cut_30\n",
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input  eng_cut_40\n",
      "Run directory Si_gs_convergence\n",
      "Skip the computation for input  eng_cut_50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'xml_data': 'Si_gs_convergence/eng_cut_20.save/data-file-schema.xml'},\n",
       " 1: {'xml_data': 'Si_gs_convergence/eng_cut_30.save/data-file-schema.xml'},\n",
       " 2: {'xml_data': 'Si_gs_convergence/eng_cut_40.save/data-file-schema.xml'},\n",
       " 3: {'xml_data': 'Si_gs_convergence/eng_cut_50.save/data-file-schema.xml'},\n",
       " 4: {'xml_data': 'Si_gs_convergence/code_number2.save/data-file-schema.xml'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the run information of the code2 are not printed since verbose = False has been provided when the run has been appended.\n",
    "\n",
    "The run method returns the attribute .results of the Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'xml_data': 'Si_gs_convergence/eng_cut_20.save/data-file-schema.xml'},\n",
       " 1: {'xml_data': 'Si_gs_convergence/eng_cut_30.save/data-file-schema.xml'},\n",
       " 2: {'xml_data': 'Si_gs_convergence/eng_cut_40.save/data-file-schema.xml'},\n",
       " 3: {'xml_data': 'Si_gs_convergence/eng_cut_50.save/data-file-schema.xml'},\n",
       " 4: {'xml_data': 'Si_gs_convergence/code_number2.save/data-file-schema.xml'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation allows to parse the data after the execution of the dataset and/or to choose a parser \n",
    "among several choices. \n",
    "\n",
    "The parser can be chosen at this stage, for instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to perform the parsing of the results is a posteriori from the run of the dataset.\n",
    "\n",
    "For instance we can parse the results with the PwParser class of this package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse file : Si_gs_convergence/eng_cut_20.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/eng_cut_30.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/eng_cut_40.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/eng_cut_50.save/data-file-schema.xml\n",
      "Parse file : Si_gs_convergence/code_number2.save/data-file-schema.xml\n"
     ]
    }
   ],
   "source": [
    "from mppi import Parsers as P\n",
    "\n",
    "results = {}\n",
    "for run,data in gs_convergence.results.items():\n",
    "    results[run] = P.PwParser(data['xml_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <mppi.Parsers.PwParser.PwParser at 0x7f15a80a1a20>,\n",
       " 1: <mppi.Parsers.PwParser.PwParser at 0x7f158f043748>,\n",
       " 2: <mppi.Parsers.PwParser.PwParser at 0x7f158f040e48>,\n",
       " 3: <mppi.Parsers.PwParser.PwParser at 0x7f158f029fd0>,\n",
       " 4: <mppi.Parsers.PwParser.PwParser at 0x7f158efe7860>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results dictionary is something different from gs_convergence, however the results associate to the key \"i\"\n",
    "correspond to the i-th element appended to the run.\n",
    "\n",
    "The input parameters associated to each key of results are written inside the gs_convergence_runs[key] list.\n",
    "\n",
    "For instance the total energy is extracted as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0 energy -7.870821313426413\n",
      "run 1 energy -7.872953197509275\n",
      "run 2 energy -7.874327291306248\n",
      "run 3 energy -7.874492376334014\n",
      "run 4 energy -7.874513952356973\n"
     ]
    }
   ],
   "source": [
    "for run,res in results.items():\n",
    "    print('run',run,'energy',res.get_energy(convert_eV=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the post processing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Parsing, or other more specific procedures, can be performed directly when the run method is called.\n",
    "\n",
    "To do so, we define a post processing function and pass it to the Dataset. \n",
    "\n",
    "The class will apply this function when the run of the Dataset is complete. For istance in this way we can directyl \n",
    "extract the total energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_energy(data):\n",
    "    from mppi import Parsers as P\n",
    "    energy = {}\n",
    "    for run,data in data.results.items():\n",
    "        results = P.PwParser(data['xml_data'],verbose=False)\n",
    "        energy[run] = results.get_energy(convert_eV = False)\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_convergence.set_postprocessing_function(extract_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that the post processing function is passed to dataset it is directly applied when the run is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: -7.870821313426413,\n",
       " 1: -7.872953197509275,\n",
       " 2: -7.874327291306248,\n",
       " 3: -7.874492376334014,\n",
       " 4: -7.874513952356973}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.update_global_options(verbose=False)\n",
    "gs_convergence.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the attribute results contains always the name of the xml data, the post processed results\n",
    "can be accessed in the class as self.post_processing(). \n",
    "\n",
    "For this reason the method fetch_results has been slightly modified with respect to the original implementation\n",
    "of PyBigDFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in this case the post processing function directly returns the energy we can use the method fetch_results without specifying the\n",
    "\n",
    "attribute to extract the energy for a specific value of the energy cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-7.872953197509275]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.fetch_results(id={'eng_cut' : 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the fetch_results method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible approach is to define a post processing function that perform a simple parsing of the data.\n",
    "\n",
    "Then we can use fetch_results to seek for the attribute energy in the computation(s) that match the id \n",
    "passed in fetch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data):\n",
    "    from mppi import Parsers as P\n",
    "    results = {}\n",
    "    for run,data in data.results.items():\n",
    "        results[run] = P.PwParser(data['xml_data'],verbose=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_convergence.set_postprocessing_function(parse_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <mppi.Parsers.PwParser.PwParser at 0x7f15a80a17f0>,\n",
       " 1: <mppi.Parsers.PwParser.PwParser at 0x7f15a80a1c18>,\n",
       " 2: <mppi.Parsers.PwParser.PwParser at 0x7f158ef0a7f0>,\n",
       " 3: <mppi.Parsers.PwParser.PwParser at 0x7f158eec6d68>,\n",
       " 4: <mppi.Parsers.PwParser.PwParser at 0x7f158ee869b0>}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-7.874492376334014]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_convergence.fetch_results(id={'eng_cut': 50},attribute='energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of the seek_convergence method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the functionality of this method by performing a second convergence test on the number of kpoints.\n",
    "\n",
    "In this example we set the energy cutoff to 60 Ry and build a new dataset appending run with increasing number of\n",
    "kpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = I.PwInput('IO_files/si_scf.in')\n",
    "inp.set_energy_cutoff(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a QuantumESPRESSO calculator with OMP_NUM_THREADS=1 and command mpirun -np 4 pw.x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'omp': 1,\n",
       " 'mpi_run': 'mpirun -np 4',\n",
       " 'executable': 'pw.x',\n",
       " 'skip': True,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = C.QeCalculator(skip=True,verbose=False)\n",
    "code.global_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kpoint = D.Dataset(label='Si_kpoints_convergence',run_dir='Si_gs_convergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpoints = [2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in kpoints:\n",
    "    id = {'kp':k}\n",
    "    inp.set_kpoints(points = [k,k,k])\n",
    "    inp.set_prefix(U.name_from_id(id))\n",
    "    gs_kpoint.append_run(id=id,runner=code,input=inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runs have been appended but not performed, then we call seek_convergence.\n",
    "\n",
    "We want to perform a convergence procedure based on the value of the total energy of the system.\n",
    "So we have to define a post processing function that provide this quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_energy(data):\n",
    "    from mppi import Parsers as P\n",
    "    energy = {}\n",
    "    for run,data in data.results.items():\n",
    "        results = P.PwParser(data['xml_data'],verbose=False)\n",
    "        energy[run] = results.get_energy(convert_eV = False)\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kpoint.set_postprocessing_function(extract_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching results for id \" {'kp': 2} \"\n",
      "Fetching results for id \" {'kp': 3} \"\n",
      "Fetching results for id \" {'kp': 4} \"\n",
      "Fetching results for id \" {'kp': 5} \"\n",
      "Convergence reached in Dataset \"Si_kpoints_convergence\" for id \" {'kp': 4} \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'kp': 4}, -7.874513952262473)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_kpoint.seek_convergence(rtol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seek_converge runs all the computation (in the order provided by append_run) until convergence is reached.\n",
    "Otherwise it is possible to pass a list of ids as argument of the method, in this case the calculation are restricted\n",
    "to the simulations associated to the provided ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a set of Hartree-Fock computations with Yambo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset can be used to organize Yambo computation in an analogous way of the QE ones. The differences are represented by the usage of YamboIn to build the input files, the usage of YamboCalculator to run the computations and by the pre_processing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize a Yambo calculator with command OMP_NUM_THREADS=1 mpirun -np 4 yambo\n",
      "Suffix for post_processing :  hf\n"
     ]
    }
   ],
   "source": [
    "code = C.YamboCalculator(omp=1,mpi_run='mpirun -np 4',executable='yambo',suffix='hf',verbose=True,skip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "yambo_hf = D.Dataset(label='Hatree-Fock',run_dir='yambo_hf',pre_processing='yambo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the pre_processing function _has to be_ called before appending the runs because the YamboIn class neeeds the SAVE folder to init the input object.\n",
    "\n",
    "The dataset make usage of __one__ nscf computation to build the SAVE folder that is used in all the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'si_nscf/k_6.save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create folder yambo_hf\n",
      "execute :  cd si_nscf/k_6.save/;p2y -a 2\n",
      "execute :  cp -r si_nscf/k_6.save//SAVE yambo_hf\n",
      "execute :  cd yambo_hf;OMP_NUM_THREADS=1 yambo\n"
     ]
    }
   ],
   "source": [
    "yambo_hf.pre_processing_function(source_dir=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the runs can be appended to the dataset. For instance we perform parametric runs in terms of the EXXRLvcs parameter that expresses the energy cutoff in the number of g-components of G0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "exx_values = [2.,3.,4.] #in Hartree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "yambo_in = I.YamboIn('yambo -x -V rl',folder=yambo_hf.run_dir)\n",
    "\n",
    "for ex in exx_values:\n",
    "    idd = {'EXXRLvcs' : ex} \n",
    "    yambo_in['EXXRLvcs'] = [1000.0*ex,'mHa']\n",
    "    yambo_hf.append_run(id=idd,calculator=code,input=yambo_in)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'EXXRLvcs': 2.0}, {'EXXRLvcs': 3.0}, {'EXXRLvcs': 4.0}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yambo_hf.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_and_locXC\n",
      "FFTGvecs = 2133.000000 RL\n",
      "SE_Threads = 0.000000e+00 \n",
      "EXXRLvcs = 2000.000000 mHa\n",
      "% QPkrange\n",
      " 1 | 32 | 1 | 10 |   \n",
      "%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yambo_hf.runs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute : cd yambo_hf ; OMP_NUM_THREADS=1 mpirun -np 4 yambo -F EXXRLvcs_2.0.in -J EXXRLvcs_2.0 -C EXXRLvcs_2.0\n",
      "parse file : yambo_hf/EXXRLvcs_2.0/o-EXXRLvcs_2.0.hf\n",
      "execute : cd yambo_hf ; OMP_NUM_THREADS=1 mpirun -np 4 yambo -F EXXRLvcs_3.0.in -J EXXRLvcs_3.0 -C EXXRLvcs_3.0\n",
      "parse file : yambo_hf/EXXRLvcs_3.0/o-EXXRLvcs_3.0.hf\n",
      "execute : cd yambo_hf ; OMP_NUM_THREADS=1 mpirun -np 4 yambo -F EXXRLvcs_4.0.in -J EXXRLvcs_4.0 -C EXXRLvcs_4.0\n",
      "parse file : yambo_hf/EXXRLvcs_4.0/o-EXXRLvcs_4.0.hf\n"
     ]
    }
   ],
   "source": [
    "yambo_hf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be extraced in various ways, both using the fetch_results methods or by direct access to the attribute of the Yambo parser. Here we provide some examples.\n",
    "\n",
    "First of all we can see the names of the attributes for each elements of yambo_hf.results as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['K-point', 'Band', 'Eo', 'Ehf', 'DFT', 'HF'])\n"
     ]
    }
   ],
   "source": [
    "keys = yambo_hf.results[0].getAttributes()\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can access to the values directly as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-18.69873, -1.207, -1.438, -0.62819, 6.98599]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yambo_hf.results[0].Ehf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by using the fetch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-18.69873, -1.207, -1.438, -0.62819, 6.98599]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yambo_hf.fetch_results(id={'EXXRLvcs' : 2.0},attribute='Ehf')[0][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can use fetch_results to extract the computation(s) that we need and then access directly to the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-18.69873, -1.207, -1.438, -0.62819, 6.98599]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yambo_hf.fetch_results(id={'EXXRLvcs' : 2.0})[0].Ehf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
